
===============================
Replica-Aware Slowdown Predictor
===============================

üìå Purpose:
Predict normalized tail-latency slowdown (norm_perf = baseline_P99 / observed_P99)
based on live Intel PCM hardware metrics, replica count, and RPS.

üéØ Inputs to the Model:
- Sliding-window statistics (mean, std, p95) from Intel PCM logs
  ‚Ä¢ Metrics include IPC, L2MISS, L3MISS, PhysIPC%, and C-state residencies
  ‚Ä¢ Computed per core (3, 4, 5) and also as averaged aggregates
- Given RPS (traffic load)
- Number of replicas already placed on the node

üéØ Output:
- Predicted normalized slowdown (norm_perf), e.g., 1.2 ‚Üí 20% latency increase

üß† Model Architecture:
- StandardScaler: normalizes all input features
- PolynomialFeatures (degree=2): captures interactions between metrics
- PCA: reduces dimensionality while retaining 95% variance
- RandomForestRegressor: robust nonlinear predictor

üìÅ Saved Model:
- Path: models/slowdown_predictor.pkl
- Format: scikit-learn Pipeline (joblib)

üìä Evaluation Summary:
- R¬≤ Score: High (‚âà 0.95 on test set)
- MAE: Low (‚âà 0.04)
- PCA retained variance: 95%

üîÅ Training Dataset:
- Derived from 24 test scenarios across 4 replica levels, 9 RPS values, and multiple interference setups
- Each sample summarizes a 180s workload run via 36-row PCM log

üîÑ Use Case in Scheduler:
At pod placement time:
  1. Collect live PCM metrics
  2. Add intended replica count and known/forecasted RPS
  3. Predict expected slowdown (norm_perf)
  4. Compute RiskScore = 1 / norm_perf
  5. Choose node with lowest RiskScore

===============================
üîß Recommendations for Improvement
===============================
1. üîç Feature Selection:
   - Consider using mutual information or SHAP values to prune weak features
   - Try ablation testing to confirm which PCM metrics matter most

2. üß™ Data Expansion:
   - Run more scenarios (especially for overlapping RPS/replica ranges)
   - Add controlled noise or jitter to simulate real-world metrics

3. üå≤ Model Alternatives:
   - Try XGBoost or LightGBM with early stopping
   - Consider a model ensemble (RandomForest + XGBoost + Ridge)

4. üîÅ Drift Detection:
   - Monitor real vs. predicted norm_perf over time in production
   - Trigger retraining when drift exceeds a threshold

5. ‚öôÔ∏è Multi-Objective Extension:
   - Extend model output to include energy or cost if system metrics allow
   - Useful for joint optimization (latency vs. energy vs. placement density)

6. üìà SHAP Analysis:
   - Use TreeExplainer for detailed feature attributions
   - Plot feature importances to drive system tuning



=======================================================================
from xgboost import XGBRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score

X = df_ml[feature_cols]
y = df_ml["norm_perf"]

X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)

model = XGBRegressor(
    n_estimators=200,
    max_depth=4,
    learning_rate=0.05,
    subsample=0.9,
    colsample_bytree=0.8,
    reg_lambda=1.0,
    random_state=42
)

model.fit(X_train, y_train, early_stopping_rounds=10, eval_set=[(X_test, y_test)], verbose=True)

y_pred = model.predict(X_test)
print("MAE:", mean_absolute_error(y_test, y_pred))
print("R¬≤:", r2_score(y_test, y_pred))










import re

def extract_pcm_features(data_dir, target_cores=[3,4,5], include_system=False, window_size=2, stats=('mean','p95','std')):
    """
    Extract PCM features from core and optionally system CSV logs.
    
    Parameters:
    - data_dir (str): Directory containing PCM CSV files
    - target_cores (list): Core numbers to analyze (default: [3,4,5])
    - include_system (bool): Whether to include system-wide metrics
    - window_size (int): Samples for rolling window
    - stats (tuple): Statistics to compute ('mean','p95','std','max','min')
    
    Returns:
    - pd.DataFrame: One row per scenario, features + pcm_id
    """
    # Pattern to match both core and system files
    core_pattern = os.path.join(data_dir, 'pcm_core_*.csv')
    system_pattern = os.path.join(data_dir, 'pcm_system_*.csv')
    
    # Get all available files
    core_files = glob.glob(core_pattern)
    system_files = glob.glob(system_pattern) if include_system else []
    
    if not core_files and not system_files:
        print(f"‚ö†Ô∏è No PCM files found in {data_dir}")
        return pd.DataFrame()

    # Create mapping of scenario IDs to their features
    features_dict = {}

    # Process core files
    for filepath in core_files:
        # Extract pcm_id (e.g., "2replicas_scenario9_900rps" from "pcm_core_2replicas_scenario9_900rps.csv")
        pcm_id = os.path.basename(filepath).replace('pcm_core_', '').replace('.csv', '')
        
        if pcm_id not in features_dict:
            features_dict[pcm_id] = {'Test_ID': pcm_id}
        
        # Try extracting RPS and Replicas from ID
        match_rps = re.search(r'(\d+)rps', pcm_id)
        match_rep = re.search(r'(\d+)replicas', pcm_id)
        if match_rps:
            features_dict[pcm_id]['RPS'] = int(match_rps.group(1))
        if match_rep:
            features_dict[pcm_id]['Replicas'] = int(match_rep.group(1))
            
        df_pcm = pd.read_csv(filepath)
        
        # Collect per-core feature matrix
        core_metrics_group = {}  # for later aggregation

        # Process target cores
        for core in target_cores:
            core_prefix = f'Core{core} (Socket 0) - '
            core_cols = [col for col in df_pcm.columns if col.startswith(core_prefix)]
            
            # Filter to metrics we care about
            keep_metrics = ['IPC', 'L3MISS', 'L2MISS', 'C0res%', 'C1res%', 'C6res%']
            core_cols = [col for col in core_cols if any(m in col for m in keep_metrics)]
            
            for col in core_cols:
                metric = col.replace(core_prefix, '').replace('%', '')
                clean_name = f'Core{core}_{metric}'
                s = df_pcm[col]
                
                # Compute statistics
                stats_results = compute_windowed_stats(s, window_size, stats)
                for stat, value in stats_results.items():
                    features_dict[pcm_id][f'{stat}_{clean_name}'] = value
                
                # Store for aggregation
                key = f'{metric}'
                if key not in core_metrics_group:
                    core_metrics_group[key] = []
                core_metrics_group[key].append(s)

        # Don't know if this is needed, but keeping it for now
        
        # Compute aggregated stats across cores
        for metric, series_list in core_metrics_group.items():
            df_metric = pd.concat(series_list, axis=1)
            agg_series = df_metric.mean(axis=1)  # row-wise avg across cores
            agg_stats = compute_windowed_stats(agg_series, window_size, stats)
            for stat, value in agg_stats.items():
                features_dict[pcm_id][f'{stat}_AvgCore_{metric}'] = value

    # Process system files if requested
    if include_system:
        for filepath in system_files:
            pcm_id = os.path.basename(filepath).replace('pcm_system_', '').replace('.csv', '')
            
            if pcm_id not in features_dict:
                features_dict[pcm_id] = {'pcm_id': pcm_id}
                
            df_sys = pd.read_csv(filepath)
            
            # Filter system metrics (excluding core-specific and unwanted metrics)
            sys_cols = [col for col in df_sys.columns 
                       if 'Core' not in col and 
                       not any(x in col for x in ["System Pack C-States", "PhysIPC%"])]
            
            for col in sys_cols:
                if ' - ' in col:
                    metric = col.split(' - ')[1].replace('%', '')
                    clean_name = f'Sys_{metric}'
                else:
                    clean_name = f'Sys_{col}'
                    
                s = df_sys[col]
                stats_results = compute_windowed_stats(s, window_size, stats)
                for stat, value in stats_results.items():
                    features_dict[pcm_id][f'{stat}_{clean_name}'] = value

    # Convert to DataFrame
    df_features = pd.DataFrame(features_dict.values())
    df_features = df_features[["Test_ID"] + sorted([c for c in df_features.columns if c != "Test_ID"])]
    print(f"‚úÖ Extracted {len(df_features.columns)-1} features from {len(df_features)} scenarios in {data_dir}")
    return df_features