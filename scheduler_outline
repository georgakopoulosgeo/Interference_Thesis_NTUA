KUBERNETES ML-DRIVEN SCHEDULER ARCHITECTURE

Core Components:
─────────────────────────────────────────────────

1. Nginx and Redis
      • Nginx : HTTP server
      • Redis : In-memory data structure store
      • Used for offline training of the ML model

2. Azure Trace Data
   • Source: Real-world VM/workload traces from Azure Public Dataset.
   • Content: Timestamped RPS (requests/sec) and CPU usage over 30 minutes.
   • Role: Provides realistic traffic patterns to replace synthetic wrk2 loads.
   • Preprocessing: Align trace timestamps with experiment steps (e.g., map RPS to Nginx load).

2. ARIMA Forecasting Service
   • Input: Historical RPS data from Azure traces.
   • Output: Predicted RPS for next 2 minutes → computes desired_replicas.
   • Formula: desired_replicas = ceil(predicted_RPS / max_RPS_per_replica).
   • Deployment: Flask API (/forecast endpoint) running in Kubernetes.

3. Intel PCM Metrics Collector 
   • Tool: Intel Performance Counter Monitor (PCM) running as a DaemonSet on each node.
   • Metrics: IPC, L2/L3 cache misses, memory bandwidth, CPU utilization.
   • Sampling: 20-second windows (adjustable) to balance accuracy/overhead.
   • Output: CSV/JSON logs sent to the Predictor API.

4. Replica-Aware Predictor API Service
   • Model: RandomForest/XGBoost trained per replica count (1–4 replicas).
   • Input Features:
      - PCM metrics (IPC, cache misses, etc.).
      - Current replica count on the target node.
      - Azure RPS forecast (optional).
   • Output: Predicted slowdown ratio (P99 / baseline_P99).
   • Deployment: Flask API (/predict endpoint).

5. Custom Scheduler
   • Logic:
      1. Queries ARIMA for desired_replicas.
      2. Evaluates all nodes using the Predictor’s slowdown scores.
      3. Selects (node, replicas) with lowest RiskScore (slowdown + replica penalty).
   • Integration: Kubernetes Scheduler Extender or custom scheduler binary.
   • Cost Function:
python RiskScore = (predicted_slowdown) + 0.1 * |actual_replicas - desired_replicas|

6. Kubernetes Cluster
   • Nodes: 2+ physical/virtual machines.
   • Workloads:
      - Primary: Nginx (latency-sensitive, scaled via desired_replicas).
      - Interference: Redis + iBench (stressors for CPU/LLC/memory contention).
   • Traffic Generator: Modified wrk2 to replay Azure trace RPS.


Data Flow:
─────────────────────────────────────────────────
Azure Trace → ARIMA forecasts RPS → computes desired_replicas.
PCM Collector → streams metrics to Predictor API.
Predictor → evaluates slowdowns for all (node, replica) combinations.
Scheduler → selects optimal (node, replicas) pair → deploys pods via Kubernetes API.


Key Characteristics: 
─────────────────────────────────────────────────
   • Self-contained benchmark pods (Nginx + wrk)
   • Hardware-level metrics via PCM
   • ML model evaluating node fitness
   • Replica-aware placement decisions
   • Isolated traffic per test pod
   • Comparison against default scheduler

Key Files to Implement
─────────────────────────────────────────────────
- pcm-daemonset.yaml
   Deploys PCM as a DaemonSet with privileged access to PMU.
- arima-forecast.py
   ARIMA training/forecasting script (containerized as Flask API).
- predictor-api.py
   Predictor service with pre-trained RandomForest model.
- scheduler-extender.yaml
   Kubernetes scheduler configuration for custom logic.

Optional Extensions:
─────────────────────────────────────────────────
Multi-Trace Validation: Test on Google ClusterData2019 (beyond Azure).
Out-of-Distribution Workloads: Add Cassandra/Spark to test generalization.
Online Learning: Retrain predictor periodically with new PCM data.
Fallback Mode: Revert to default scheduler if predictor fails.
Energy-Aware: Add RAPL metrics to predictor inputs.
Explainability: Use SHAP values to explain high RiskScores.


================================================================================================
================================================================================================

               ┌────────────────────────────┐
               │      Traffic Generator     │
               │  • Sends dynamic HTTP load │
               │  • Used for profiling & RT │
               └────────────┬───────────────┘
                            │
                            ▼
               ┌────────────────────────────┐
               │         Controller         │
               │                            │
               │  ┌──────────────────────┐  │
               │  │   1. ARIMA Module    │  │
               │  │   • Forecast RPS     │  │
               │  └──────────────────────┘  │
               │                            │
               │  ┌──────────────────────┐  │
               │  │  2. Lookup Table     │  │
               │  │  • RPS → Replicas    │  │
               │  └──────────────────────┘  │
               │                            │
               │  ┌──────────────────────┐  │
               │  │ 3. Placement Logic   │  │
               │  │ • Decide best layout │  │
               │  └──────────────────────┘  │
               └────────────────────────────┘

================================================================================================
================================================================================================

               ┌────────────────────────────┐
               │      Traffic Generator     │
               │  • Sends dynamic HTTP load │
               └────────────┬───────────────┘
                            │
                            ▼
               ┌────────────────────────────┐
               │       Naive Controller     │
               │                            │
               │  ┌──────────────────────┐  │
               │  │   ARIMA Module       │  │
               │  │  • Forecast next RPS │  │
               │  └──────────────────────┘  │
               │                            │
               │  ┌──────────────────────┐  │
               │  │  Replica Lookup      │  │
               │  │  • RPS → Replicas    │  │
               │  └──────────────────────┘  │
               │                            │
               │  ❌ No Placement Decision  │
               │  ✔ Only Scales Deployment  │
               └────────────┬───────────────┘
                            │
                            ▼
               ┌────────────────────────────┐
               │       Kube Scheduler       │
               │  • Chooses node for pods   │
               │  • Based on CPU/mem reqs   │
               └────────────┬───────────────┘
                            │
                            ▼
               ┌────────────────────────────┐
               │    Kubernetes Cluster      │
               │  • Pods distributed across │
               │    Node1 (cores 0–2)       │
               │    Node2 (cores 3–5)       │
               └────────────────────────────┘

================================================================================================
================================================================================================

               ┌────────────────────────────┐
               │       MARLA Controller     │
               │  (Runs every 60 seconds)   │
               └────────────┬───────────────┘
                            │
        ┌───────────────────┼───────────────────┐
        ▼                   ▼                   ▼
┌────────────────┐  ┌────────────────────┐  ┌────────────────────────┐
│  ARIMA Module  │  │ Replica Lookup     │  │ Slowdown Predictor API │
│ • Forecast RPS │  │ • RPS → Replicas   │  │ • Input: metrics+rps   │
└────────────────┘  └────────────────────┘  │ • Output: slowdown     │
                                            └─────────┬──────────────┘
                                                      │
                                                      ▼
                                        ┌──────────────────────────────┐
                                        │ Placement Optimizer Logic    │
                                        │ • Try all (r1, r2) splits    │
                                        │   Where r1+r2=replicas needed│
                                        │ • Compute score = (r1×np1 +  │
                                        │    r2×np2) / (r1 + r2)       │
                                        │ • Penalize empty nodes       │
                                        └────────────┬─────────────────┘
                                                     │
                                                     ▼
                                        ┌──────────────────────────────┐
                                        │ Kubernetes API Interaction   │
                                        │ • Apply new replica plan     │
                                        │ • Build Deployment if needed │
                                        └────────────┬─────────────────┘
                                                     │
                                                     ▼
                                        ┌─────────────────────────────┐
                                        │       Kubernetes Cluster    │
                                        │ • Nodes: Node1 / Node2      │
                                        │ • Nginx + iBench workloads  │
                                        └─────────────────────────────┘
